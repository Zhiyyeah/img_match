import netCDF4 as nc
import numpy as np
import platform

def analyze_goci2_file(file_path):
    """
    åˆ†æGOCI2 L1B NetCDFæ–‡ä»¶çš„ç»“æ„å’Œå˜é‡ä¿¡æ¯
    """
    try:
        # æ‰“å¼€NetCDFæ–‡ä»¶
        dataset = nc.Dataset(file_path, 'r')
        
        print("=" * 80)
        print(f"æ–‡ä»¶è·¯å¾„: {file_path}")
        print("=" * 80)
        
        # 1. æ˜¾ç¤ºå…¨å±€å±æ€§
        print("\nğŸ“‹ å…¨å±€å±æ€§:")
        print("-" * 50)
        for attr_name in dataset.ncattrs():
            attr_value = dataset.getncattr(attr_name)
            print(f"{attr_name}: {attr_value}")
        
        # 2. æ˜¾ç¤ºç»´åº¦ä¿¡æ¯
        print("\nğŸ“ ç»´åº¦ä¿¡æ¯:")
        print("-" * 50)
        for dim_name, dim in dataset.dimensions.items():
            size = len(dim) if not dim.isunlimited() else "æ— é™åˆ¶"
            print(f"{dim_name}: {size}")
        
        # 3. æ˜¾ç¤ºæ‰€æœ‰å˜é‡ååŠå…¶åŸºæœ¬ä¿¡æ¯
        print("\nğŸ“Š æ ¹çº§åˆ«å˜é‡åˆ—è¡¨:")
        print("-" * 50)
        if dataset.variables:
            for var_name, var in dataset.variables.items():
                # è·å–å˜é‡çš„ç»´åº¦ã€æ•°æ®ç±»å‹å’Œå½¢çŠ¶
                dimensions = var.dimensions
                dtype = var.dtype
                shape = var.shape
                
                print(f"\nå˜é‡å: {var_name}")
                print(f"  - æ•°æ®ç±»å‹: {dtype}")
                print(f"  - ç»´åº¦: {dimensions}")
                print(f"  - å½¢çŠ¶: {shape}")
                
                # æ˜¾ç¤ºå˜é‡å±æ€§
                if var.ncattrs():
                    print("  - å±æ€§:")
                    for attr_name in var.ncattrs():
                        attr_value = var.getncattr(attr_name)
                        # å¦‚æœå±æ€§å€¼å¤ªé•¿ï¼Œåªæ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
                        if isinstance(attr_value, str) and len(attr_value) > 100:
                            attr_value = attr_value[:100] + "..."
                        print(f"    {attr_name}: {attr_value}")
        else:
            print("æ ¹çº§åˆ«æ²¡æœ‰å˜é‡ï¼Œå˜é‡å¯èƒ½å­˜å‚¨åœ¨ç»„ä¸­")
        
        # 4. æ£€æŸ¥å¹¶æ˜¾ç¤ºç»„ç»“æ„ä¸­çš„å˜é‡ï¼ˆHDF5æ ¼å¼ç‰¹æœ‰ï¼‰
        total_variables = len(dataset.variables)
        if hasattr(dataset, 'groups') and dataset.groups:
            print("\nğŸ—‚ï¸ ç»„ç»“æ„åŠå…¶å˜é‡:")
            print("-" * 50)
            for group_name, group in dataset.groups.items():
                print(f"\nğŸ“ ç»„å: {group_name}")
                print(f"  ç»´åº¦æ•°é‡: {len(group.dimensions)}")
                print(f"  å˜é‡æ•°é‡: {len(group.variables)}")
                
                # æ˜¾ç¤ºç»„çš„ç»´åº¦
                if group.dimensions:
                    print("  ğŸ“ ç»„ç»´åº¦:")
                    for dim_name, dim in group.dimensions.items():
                        size = len(dim) if not dim.isunlimited() else "æ— é™åˆ¶"
                        print(f"    {dim_name}: {size}")
                
                # æ˜¾ç¤ºç»„ä¸­çš„å˜é‡
                if group.variables:
                    print("  ğŸ“Š ç»„å˜é‡:")
                    for var_name, var in group.variables.items():
                        dimensions = var.dimensions
                        dtype = var.dtype
                        shape = var.shape
                        total_variables += 1
                        
                        print(f"\n    å˜é‡å: {var_name}")
                        print(f"      - æ•°æ®ç±»å‹: {dtype}")
                        print(f"      - ç»´åº¦: {dimensions}")
                        print(f"      - å½¢çŠ¶: {shape}")
                        
                        # æ˜¾ç¤ºå˜é‡å±æ€§
                        if var.ncattrs():
                            print("      - å±æ€§:")
                            for attr_name in var.ncattrs():
                                attr_value = var.getncattr(attr_name)
                                # å¦‚æœå±æ€§å€¼å¤ªé•¿ï¼Œåªæ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
                                if isinstance(attr_value, str) and len(attr_value) > 100:
                                    attr_value = attr_value[:100] + "..."
                                print(f"        {attr_name}: {attr_value}")
                
                # æ˜¾ç¤ºç»„çš„å…¨å±€å±æ€§
                if group.ncattrs():
                    print("  ğŸ“‹ ç»„å±æ€§:")
                    for attr_name in group.ncattrs():
                        attr_value = group.getncattr(attr_name)
                        if isinstance(attr_value, str) and len(attr_value) > 100:
                            attr_value = attr_value[:100] + "..."
                        print(f"    {attr_name}: {attr_value}")
        
        # 5. æ˜¾ç¤ºæ–‡ä»¶ç»“æ„æ‘˜è¦
        print("\n" + "=" * 80)
        print("ğŸ“ˆ æ–‡ä»¶ç»“æ„æ‘˜è¦:")
        print("=" * 80)
        print(f"ç»´åº¦æ•°é‡: {len(dataset.dimensions)}")
        print(f"æ ¹çº§åˆ«å˜é‡æ•°é‡: {len(dataset.variables)}")
        print(f"æ€»å˜é‡æ•°é‡: {total_variables}")
        print(f"ç»„æ•°é‡: {len(dataset.groups) if hasattr(dataset, 'groups') else 0}")
        print(f"å…¨å±€å±æ€§æ•°é‡: {len(dataset.ncattrs())}")
        
        # å…³é—­æ–‡ä»¶
        dataset.close()
        
        print("\nâœ… æ–‡ä»¶åˆ†æå®Œæˆ!")
        
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        print("è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        print("è¯·ç¡®ä¿:")
        print("1. æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„NetCDFæ ¼å¼")
        print("2. å·²å®‰è£…netCDF4åº“: pip install netCDF4")
        print("3. æ–‡ä»¶æ²¡æœ‰è¢«å…¶ä»–ç¨‹åºå ç”¨")

def list_variables_only(file_path):
    """
    ä»…åˆ—å‡ºå˜é‡åï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰- åŒ…æ‹¬ç»„ä¸­çš„å˜é‡
    """
    try:
        dataset = nc.Dataset(file_path, 'r')
        print(f"\nğŸ“‹ æ–‡ä»¶ä¸­çš„æ‰€æœ‰å˜é‡å:")
        print("-" * 50)
        
        var_count = 0
        
        # æ ¹çº§åˆ«å˜é‡
        if dataset.variables:
            print("ğŸ”¸ æ ¹çº§åˆ«å˜é‡:")
            for var_name in dataset.variables.keys():
                var_count += 1
                print(f"{var_count:2d}. {var_name}")
        
        # ç»„ä¸­çš„å˜é‡
        if hasattr(dataset, 'groups') and dataset.groups:
            for group_name, group in dataset.groups.items():
                if group.variables:
                    print(f"\nğŸ”¸ ç»„ '{group_name}' ä¸­çš„å˜é‡:")
                    for var_name in group.variables.keys():
                        var_count += 1
                        print(f"{var_count:2d}. {group_name}/{var_name}")
        
        print(f"\næ€»å…±æ‰¾åˆ° {var_count} ä¸ªå˜é‡")
        dataset.close()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")

def list_variables_by_group(file_path):
    """
    æŒ‰ç»„åˆ†ç±»åˆ—å‡ºæ‰€æœ‰å˜é‡å
    """
    try:
        dataset = nc.Dataset(file_path, 'r')
        print(f"\nğŸ“‹ æŒ‰ç»„åˆ†ç±»çš„å˜é‡åˆ—è¡¨:")
        print("=" * 60)
        
        # æ ¹çº§åˆ«å˜é‡
        if dataset.variables:
            print("ğŸ”¸ æ ¹çº§åˆ«å˜é‡:")
            for i, var_name in enumerate(dataset.variables.keys(), 1):
                print(f"  {i:2d}. {var_name}")
        
        # ç»„ä¸­çš„å˜é‡
        if hasattr(dataset, 'groups') and dataset.groups:
            for group_name, group in dataset.groups.items():
                if group.variables:
                    print(f"\nğŸ”¸ ç»„: {group_name}")
                    for i, var_name in enumerate(group.variables.keys(), 1):
                        print(f"  {i:2d}. {var_name}")
        
        dataset.close()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")

if __name__ == "__main__":

    file_path = r"/Users/zy/Downloads/GK2_GOCI2_L1B_20250429_021530_LA_S007.nc"

    
    print("ğŸŒŠ GOCI2 L1B NetCDFæ–‡ä»¶åˆ†æå·¥å…·")
    print("=" * 80)
    
    # æ‰§è¡Œè¯¦ç»†åˆ†æ
    analyze_goci2_file(file_path)
    
    # å¿«é€ŸæŸ¥çœ‹å˜é‡ååˆ—è¡¨
    print("\n" + "=" * 80)
    list_variables_by_group(file_path)
    
    # ä¹Ÿå¯ä»¥ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬åªæ˜¾ç¤ºå˜é‡å
    # list_variables_only(file_path)